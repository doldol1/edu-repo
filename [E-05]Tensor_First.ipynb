{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8458ae1-d543-418e-933b-96c10347fb31",
   "metadata": {},
   "source": [
    "### 가위바위보 분류기 만들기\n",
    "루브릭 및 과정\n",
    "1. 이미지 분류기 모델이 성공적으로 만들어졌는가?  \n",
    "학습과정이 정상적으로 수행되었으며, 학습 결과에 대한 그래프를 시각화(ex. train acc / train loss / val acc / val loss 등) 해 보았음  \n",
    "2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가?\n",
    "오버피팅 극복을 위하여 데이터셋의 다양성, 정규화 등을 2가지 이상 시도해보았음  \n",
    "3. 분류모델의 test accuracy가 기준 이상 높게 나왔는가?\n",
    "60% 이상 도달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436977e5-3ec2-4df4-9797-cc6dcc967f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "1.21.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d089d469-00e7-4f05-9a05-076c329ccf3c",
   "metadata": {},
   "source": [
    "데이터 로드 및 Resize  \n",
    "촬영한 사진 데이터를 불러오고, 28*28로 resize할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922927a0-cc49-4f85-91cc-3f8e64547078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b8fcff-add1-446a-a4d1-6a51e85a7368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wader\\workplace\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 변환, 한번만 할 것\n",
    "r_path='C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\rock'\n",
    "s_path='C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\scissor'\n",
    "p_path='C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\paper'\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\wader\\\\workplace')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb0bf3b-9426-4ac2-97c8-03fc5f36aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(path):\n",
    "    img_list=os.listdir(path)\n",
    "    target_size=(28,28)\n",
    "    os.chdir(path)\n",
    "    for i in img_list:\n",
    "        full_path=os.path.join(path, i)\n",
    "        big_img=Image.open(full_path)\n",
    "        sm_img=big_img.resize(target_size, Image.ANTIALIAS)\n",
    "        sm_img.save(i, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3735904d-98f3-451b-b2ee-65e001168ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wader\\AppData\\Local\\Temp\\ipykernel_30980\\2826604337.py:8: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  sm_img=big_img.resize(target_size, Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "resize_images(r_path)\n",
    "resize_images(s_path)\n",
    "resize_images(p_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacef08-0942-49b2-a275-23ac51fcdd77",
   "metadata": {},
   "source": [
    "이미지 파일을 적절하게 불러오기 위해, 교육 자료에서 제시한 함수를 수정하여 사용하였다. load_data()는 실행시 img_path로부터 rock, scissor, paper의 세 폴더에 들어가서 각 값들을 불러온다.(img_path에 rock, scissor, paper의 폴더가 각각 필요하다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66c13a3-6d15-4e0a-90d5-f96f95fc8480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 이미지 개수는 300 입니다.\n",
      "데이터의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    \n",
    "    sci_list=os.listdir(img_path+'scissor\\\\')\n",
    "    rok_list=os.listdir(img_path+'rock\\\\')\n",
    "    pap_list=os.listdir(img_path+'paper\\\\')\n",
    "    \n",
    "    \n",
    "    for file in sci_list:\n",
    "        file= img_path+'scissor\\\\'+file\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in rok_list:\n",
    "        file= img_path+'rock\\\\'+file\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in pap_list:\n",
    "        file= img_path+'paper\\\\'+file\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"데이터의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = \"C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\rock_scissor_paper\\\\\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "test_dir_path = \"C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\test\\\\rock_scissor_paper\\\\\"\n",
    "(x_test, y_test)=load_data(test_dir_path)\n",
    "x_test_norm = x_test/255.0\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train_norm.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a752db-dd8e-41a1-9811-5bf2d064c1d1",
   "metadata": {},
   "source": [
    "받아온 값을 실제로 실행시켜 보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e873cbb-9ab5-4220-b9fa-ccca4025a9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[200])\n",
    "print(y_train[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c62ed4-dc01-438f-bfe6-cb20238019ee",
   "metadata": {},
   "source": [
    "딥러닝 네트워크 설계: 1차 시도는 학습자료에 나온대로 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a5df72-9c43-4f66-a512-a08e643aecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b825ae67-decd-41da-bf08-0aaf2fc6daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5dd6e45-964b-411c-bfa7-f3b565716bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                25632     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "179f1f79-47f2-4e23-80d1-26656e18eaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 6ms/step - loss: 1.0993 - accuracy: 0.3367\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0500 - accuracy: 0.6100\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9958 - accuracy: 0.5900\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8873 - accuracy: 0.6800\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.7418 - accuracy: 0.6867\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5984 - accuracy: 0.7367\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5429 - accuracy: 0.7467\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4577 - accuracy: 0.7800\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4121 - accuracy: 0.7767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ade161ca0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8708e5a3-8cc3-47cf-9897-d1505d9bf92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.3707 - accuracy: 0.4100 - 338ms/epoch - 34ms/step\n",
      "test_loss: 1.3707098960876465\n",
      "test_accuracy: 0.4099999964237213\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss}\")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062a823-cf2a-446a-ac00-43d18dced611",
   "metadata": {},
   "source": [
    "예상했던 대로 높은 수치의 값이 나오지 않았다. 반복하여 돌렸을 때, 0.3에서 0.5 정도의 값이 나왔으며, 0.5가 나왔다고 한들 큰 의미를 두기는 어려워 보인다. 데이터셋, 모델 설계, 매개변수 등 다양한 요소들에 대해 실험해 보도록 하자. 먼저, 가장 쉽게 할 수 있는 매개변수 조작부터 실행해 보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72e51e27-7510-4c4c-8e2b-852b846b6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_1=128\n",
    "n_channel_2=256\n",
    "n_dense=50\n",
    "n_train_epoch=20\n",
    "\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d25653a4-a59c-4910-9ef4-91297571ab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 2s 109ms/step - loss: 1.1445 - accuracy: 0.3467\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 1.0402 - accuracy: 0.4633\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 1s 137ms/step - loss: 0.8252 - accuracy: 0.7067\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.5639 - accuracy: 0.7367\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 0.4376 - accuracy: 0.7967\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.3741 - accuracy: 0.8600\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.3849 - accuracy: 0.7867\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.3467 - accuracy: 0.8467\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 1s 136ms/step - loss: 0.2591 - accuracy: 0.9033\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.2224 - accuracy: 0.9333\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.2183 - accuracy: 0.9067\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.1526 - accuracy: 0.9533\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.1020 - accuracy: 0.9833\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 0.0732 - accuracy: 0.9900\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.0564 - accuracy: 0.9933\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 0.0448 - accuracy: 0.9967\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 0.0355 - accuracy: 0.9933\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0164 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ae1447b50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87d0d218-921b-44b9-9447-4be7a08e06ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - loss: 2.2947 - accuracy: 0.5633 - 952ms/epoch - 95ms/step\n",
      "test_loss: 2.2947001457214355\n",
      "test_accuracy: 0.5633333325386047\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss}\")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0916b9bf-a80e-4655-bfd7-be53639c0ac5",
   "metadata": {
    "tags": []
   },
   "source": [
    "여러번의 시행을 해봤지만 만족할만한 결과를 얻을 수는 없었다. 모델은 낮게는 0.35, 높게는 0.50 대의 정확도를 보여주었으며, 거의 달라진 것은 없었다. 그래서 통합 데이터셋을 사용하였다.\n",
    "# 통합 데이터셋 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4c01b5d-a86b-43e5-9dba-3c9fa03d249e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wader\\AppData\\Local\\Temp\\ipykernel_30980\\2826604337.py:8: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  sm_img=big_img.resize(target_size, Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "# 통합 데이터셋 변환 한번만 할 것\n",
    "r_path='C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\ent_data\\\\rock_scissor_paper\\\\rock'\n",
    "s_path='C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\ent_data\\\\rock_scissor_paper\\\\scissor'\n",
    "p_path='C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\ent_data\\\\rock_scissor_paper\\\\paper'\n",
    "\n",
    "\n",
    "resize_images(r_path)\n",
    "resize_images(s_path)\n",
    "resize_images(p_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43b8bc7b-8f7f-4e86-97b1-6dc518cb871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data_ent(img_path, number_of_data=7372):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    \n",
    "    sci_list=os.listdir(img_path+'scissor\\\\')\n",
    "    rok_list=os.listdir(img_path+'rock\\\\')\n",
    "    pap_list=os.listdir(img_path+'paper\\\\')\n",
    "    \n",
    "    \n",
    "    for file in sci_list:\n",
    "        file= img_path+'scissor\\\\'+file\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in rok_list:\n",
    "        file= img_path+'rock\\\\'+file\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in pap_list:\n",
    "        file= img_path+'paper\\\\'+file\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"데이터의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "536ad05c-d120-47a4-b657-02bdcd5dbe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 이미지 개수는 7372 입니다.\n",
      "데이터의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "ent_image_dir_path='C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\ent_data\\\\rock_scissor_paper\\\\'\n",
    "(x_train, y_train)=load_data_ent(ent_image_dir_path)\n",
    "x_train_norm = x_train/255.0   \n",
    "\n",
    "test_dir_path = \"C:\\\\Users\\\\wader\\\\workplace\\\\ess_data\\\\[E-05]Tensor_First\\\\test\\\\rock_scissor_paper\\\\\"\n",
    "(x_test, y_test)=load_data(test_dir_path)\n",
    "x_test_norm = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e495c35-79b1-4085-893d-cc437f2cdd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7372, 28, 28, 3)\n",
      "y_train shape: (7372,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: {}\".format(x_train_norm.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e036d63a-f079-4868-a926-761d2af22441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[500])\n",
    "print(y_train[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "67583806-d7e9-4517-ad76-3d8b2b38d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드 기본 레이어 및 파라미터로 테스트\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "394cae1f-601a-4fa8-acda-ef2da002470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "231/231 [==============================] - 4s 11ms/step - loss: 0.9672 - accuracy: 0.5076\n",
      "Epoch 2/10\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 0.6258 - accuracy: 0.7427\n",
      "Epoch 3/10\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 0.4377 - accuracy: 0.8303\n",
      "Epoch 4/10\n",
      "231/231 [==============================] - 3s 13ms/step - loss: 0.3098 - accuracy: 0.8840\n",
      "Epoch 5/10\n",
      "231/231 [==============================] - 2s 8ms/step - loss: 0.2411 - accuracy: 0.9102\n",
      "Epoch 6/10\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 0.1922 - accuracy: 0.9327\n",
      "Epoch 7/10\n",
      "231/231 [==============================] - 3s 14ms/step - loss: 0.1511 - accuracy: 0.9451\n",
      "Epoch 8/10\n",
      "231/231 [==============================] - 3s 13ms/step - loss: 0.1281 - accuracy: 0.9525\n",
      "Epoch 9/10\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 0.1039 - accuracy: 0.9630\n",
      "Epoch 10/10\n",
      "231/231 [==============================] - 2s 8ms/step - loss: 0.0842 - accuracy: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23a8c63cac0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e58c7560-1f9c-452e-8cb3-2e216cf106de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - loss: 2.4088 - accuracy: 0.6600 - 605ms/epoch - 60ms/step\n",
      "test_loss: 2.408834218978882\n",
      "test_accuracy: 0.6600000262260437\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss}\")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36c513-3611-4312-9871-beba6e6bc409",
   "metadata": {},
   "source": [
    "혹시 성능을 더 높힐 수 있을까 싶어 파라미터를 변경해 보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bbe1ea39-2b17-4555-820b-d8cb4c0cc834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "# 노드 기본 레이어 및 파라미터로 테스트\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=16\n",
    "n_train_epoch=15\n",
    "\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c259d54-c606-4a6b-86ff-4d08f16d014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "231/231 [==============================] - 5s 19ms/step - loss: 0.9860 - accuracy: 0.4893\n",
      "Epoch 2/15\n",
      "231/231 [==============================] - 7s 30ms/step - loss: 0.5958 - accuracy: 0.7592\n",
      "Epoch 3/15\n",
      "231/231 [==============================] - 5s 21ms/step - loss: 0.4278 - accuracy: 0.8388\n",
      "Epoch 4/15\n",
      "231/231 [==============================] - 5s 20ms/step - loss: 0.3267 - accuracy: 0.8798\n",
      "Epoch 5/15\n",
      "231/231 [==============================] - 6s 27ms/step - loss: 0.2504 - accuracy: 0.9084\n",
      "Epoch 6/15\n",
      "231/231 [==============================] - 4s 19ms/step - loss: 0.1948 - accuracy: 0.9296\n",
      "Epoch 7/15\n",
      "231/231 [==============================] - 4s 16ms/step - loss: 0.1559 - accuracy: 0.9455\n",
      "Epoch 8/15\n",
      "231/231 [==============================] - 5s 24ms/step - loss: 0.1217 - accuracy: 0.9574\n",
      "Epoch 9/15\n",
      "231/231 [==============================] - 3s 14ms/step - loss: 0.0960 - accuracy: 0.9679\n",
      "Epoch 10/15\n",
      "231/231 [==============================] - 3s 14ms/step - loss: 0.0754 - accuracy: 0.9722\n",
      "Epoch 11/15\n",
      "231/231 [==============================] - 4s 17ms/step - loss: 0.0740 - accuracy: 0.9715\n",
      "Epoch 12/15\n",
      "231/231 [==============================] - 4s 18ms/step - loss: 0.0575 - accuracy: 0.9773\n",
      "Epoch 13/15\n",
      "231/231 [==============================] - 4s 19ms/step - loss: 0.0460 - accuracy: 0.9824\n",
      "Epoch 14/15\n",
      "231/231 [==============================] - 4s 17ms/step - loss: 0.0458 - accuracy: 0.9821\n",
      "Epoch 15/15\n",
      "231/231 [==============================] - 4s 16ms/step - loss: 0.0465 - accuracy: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23af6029370>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6a58ba5a-afd1-4a3e-a1f8-e65f4826dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 3.3928 - accuracy: 0.6300 - 493ms/epoch - 49ms/step\n",
      "test_loss: 3.3928141593933105\n",
      "test_accuracy: 0.6299999952316284\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss}\")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be0bfa4-214d-465d-b5a9-e306d7b95c11",
   "metadata": {},
   "source": [
    "회고  \n",
    "지금까지 가위바위보 이미지를 인식하고 학습시켜 보았다.  \n",
    "과제를 진행하며 가장 크게 느낀 점은 데이터의 중요성이다. 직접 만든 사진들을 가지고 학습을 시도했을 때는 아무리 시도해도 0.3에서 0.5 정도의 저조한 성과를 보였고, 과제에서 주어진 매개변수를 아무리 조정해 보아도 뾰족한 성과를 낼 수 없었다. 하지만 다른 사람들의 이미지를 모아 다시 학습을 시도했을 때는 확연한 차이를 볼 수 있었다. 물론 학습을 여러번 진행하다 보면 기준보다 낮은 accuracy를 가지는 경우도 발생했지만 직접 만든 사진들에 대한 이미지 학습보다는 훨씬 accuracy가 높았으며 과제 관련 학습을 진행하였던 화요일 마지막에 '무조건 데이터가 많다고 좋은 것이 아니다'라고 주장했던 것이 생각나 민망함도 느꼈다. 하지만 과제를 진행하던 도중 성주님과 이야기를 나눌 수 있었고, 데이터가 적더라도 충분히 좋은 성과를 낼 수 있다는 사실을 결과를 통해 확인할 수 있었고 결국 데이터는 중요하지만 데이터가 전부는 아니라는 사실을 피부로 경험할 수 있었다.  \n",
    "\n",
    "두번째로 느낀 점은 노드의 파라미터를 높게 설정한다고 능사가 아니라는 점이다. 과제 baseline에 주어진 파라미터 크기가 작다는 생각에 좀 더 파라미터를 늘려 실행시켜 보았다. conv2의 출력 값은 64에서 512, dense의 unit 값은 64까지 늘려 보았지만 시간만 오래 걸리고 accuracy는 형편없었기 때문이다. 물론 baseline보다 파라미터 크기를 줄여 4~8크기의 파라미터들을 적용시켰을 때는 더더욱 성능이 떨어지긴 했지만, 적정 선 이상이라면 굳이 hidden layer의 출력값을 늘릴 필요는 없다는 결론에 다다를 수 있었다.  \n",
    "\n",
    "과제에서 아쉬운 점이 있었다면 데이터의 픽셀 수를 늘리는 시도를 하지 못했다는 것이다. 개인적으로 생각했을 때, 데이터의 정확도가 낮은 가장 큰 이유는 이미지의 픽셀이 (28, 28)이라는 작은 크기였기 때문이라고 생각한다. 약간만 확대시켜도 형태가 뭉개지는 이미지로 사람도 알아보기 힘든데, 사람을 흉내낸 기계로 알아보는 일이 여간 어려운 일이 아닌가... 하는 직관적인 생각도 들었고, 학습에 사용하기에는 픽셀 수가 적은 만큼 데이터의 특징도 적을 것이라는 생각이 들었다. 데이터의 특징이 적다는 말은 아무리 학습을 시켜도 가위바위보의 형태를 알아보는데는 한계가 있다는 말이기 때문에 만약 된다면 (224, 224) 혹은 그보다 조금 작은 크기의 이미지를 다뤄보고 싶은 생각이 있었지만 그것까지 하기에는 역부족이었음을 아쉽게 생각한다. 그래도 저번 과제보다는 괜찮은 성과가 나왔기에 만족스럽게 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91060889-fdd2-4991-b96d-3f1c40af4dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
