{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598ee455",
   "metadata": {},
   "source": [
    "# 단어 Level 번역기 만들기\n",
    "데이터는 상위 33,000개의 샘플만 사용  \n",
    "  \n",
    "  \n",
    "### 데이터 불러오기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81cd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0038d5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng         fra                                                 cc\n",
       "0  Go.        Va !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1  Go.     Marche.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2  Go.  En route !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3  Go.     Bouge !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "4  Hi.     Salut !  CC-BY 2.0 (France) Attribution: tatoeba.org #5..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "# lines.sample(5) #샘플 5개 출력\n",
    "lines.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d25b4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng         fra\n",
       "0  Go.        Va !\n",
       "1  Go.     Marche.\n",
       "2  Go.  En route !\n",
       "3  Go.     Bouge !\n",
       "4  Hi.     Salut !"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3만 3천개의 데이터만 사용한다.(train 30000, test 3000)\n",
    "lines = lines[['eng', 'fra']][:33000]\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4535d5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; Va ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; Marche. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; En route ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>&lt;sos&gt; Bouge ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>&lt;sos&gt; Salut ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>&lt;sos&gt; Salut. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Run!</td>\n",
       "      <td>&lt;sos&gt; Cours ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Run!</td>\n",
       "      <td>&lt;sos&gt; Courez ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Run!</td>\n",
       "      <td>&lt;sos&gt; Prenez vos jambes à vos cous ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Run!</td>\n",
       "      <td>&lt;sos&gt; File ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng                                         fra\n",
       "0   Go.                            <sos> Va ! <eos>\n",
       "1   Go.                         <sos> Marche. <eos>\n",
       "2   Go.                      <sos> En route ! <eos>\n",
       "3   Go.                         <sos> Bouge ! <eos>\n",
       "4   Hi.                         <sos> Salut ! <eos>\n",
       "5   Hi.                          <sos> Salut. <eos>\n",
       "6  Run!                         <sos> Cours ! <eos>\n",
       "7  Run!                        <sos> Courez ! <eos>\n",
       "8  Run!  <sos> Prenez vos jambes à vos cous ! <eos>\n",
       "9  Run!                          <sos> File ! <eos>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '<sos>'\n",
    "eos_token = '<eos>'\n",
    "# sos_token과 eos_token사이에 ' '를 추가하여야 토그나이저에서 문제를 일으키지 않는다.\n",
    "lines.fra = lines.fra.apply(lambda x : sos_token + ' ' + x + ' '+ eos_token)\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a10c2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go.</td>\n",
       "      <td>&lt;sos&gt; va ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go.</td>\n",
       "      <td>&lt;sos&gt; marche. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go.</td>\n",
       "      <td>&lt;sos&gt; en route ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go.</td>\n",
       "      <td>&lt;sos&gt; bouge ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi.</td>\n",
       "      <td>&lt;sos&gt; salut ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hi.</td>\n",
       "      <td>&lt;sos&gt; salut. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>run!</td>\n",
       "      <td>&lt;sos&gt; cours ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>run!</td>\n",
       "      <td>&lt;sos&gt; courez ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run!</td>\n",
       "      <td>&lt;sos&gt; prenez vos jambes à vos cous ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>run!</td>\n",
       "      <td>&lt;sos&gt; file ! &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng                                         fra\n",
       "0   go.                            <sos> va ! <eos>\n",
       "1   go.                         <sos> marche. <eos>\n",
       "2   go.                      <sos> en route ! <eos>\n",
       "3   go.                         <sos> bouge ! <eos>\n",
       "4   hi.                         <sos> salut ! <eos>\n",
       "5   hi.                          <sos> salut. <eos>\n",
       "6  run!                         <sos> cours ! <eos>\n",
       "7  run!                        <sos> courez ! <eos>\n",
       "8  run!  <sos> prenez vos jambes à vos cous ! <eos>\n",
       "9  run!                          <sos> file ! <eos>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 대문자 소문자 변환\n",
    "lines['eng']=lines['eng'].str.lower()\n",
    "lines['fra']=lines['fra'].str.lower()\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37d1653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[22], [22], [22]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영어 토큰화\n",
    "eng_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')   # 문자 단위로 Tokenizer를 생성합니다. \n",
    "eng_tokenizer.fit_on_texts(lines.eng)               # eng의 각 행에 토큰화를 수행\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3] # 0,1,2모두 go 기 때문에 같을 수 밖에 없으니 당황하지 말 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690fd9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 59, 2], [1, 351, 2], [1, 22, 499, 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프랑스어 토큰화\n",
    "fra_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')   # 문자 단위로 Tokenizer를 생성합니다. \n",
    "fra_tokenizer.fit_on_texts(lines.fra)                 # fra의 각 행에 토큰화를 수행\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a42d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 토큰 중 디코더 입력 데이터에 종료 토큰과 디코더 target 데이터에 시작 토큰 제거\n",
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f2950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 최대 길이: 6\n",
      "프랑스어 최대 길이: 14\n"
     ]
    }
   ],
   "source": [
    "# 패딩 길이 확인을 위해 영어와 프랑스어 시퀸스의 최대 길이를 구한다.(단어 단위)\n",
    "max_eng_seq_len=max([len(k_len) for k_len in input_text])\n",
    "max_fra_seq_len=max([len(f_len) for f_len in target_text])\n",
    "print(\"영어 최대 길이:\", max_eng_seq_len)\n",
    "print(\"프랑스어 최대 길이:\", max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83078ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 6)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 14)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 14)\n"
     ]
    }
   ],
   "source": [
    "encoder_input= pad_sequences(encoder_input, maxlen=max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "469517d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0f2b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 4799\n",
      "프랑스어 단어장의 크기 : 10009\n"
     ]
    }
   ],
   "source": [
    "# 각 단어장 크기 확인\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd247fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_input = to_categorical(encoder_input)\n",
    "# decoder_input = to_categorical(decoder_input)\n",
    "# decoder_target = to_categorical(decoder_target)\n",
    "# print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "# print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "# print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2759c87e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 6)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 14)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30000, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노드와 마찬가지로 3000건만 검증데이터로 준다.\n",
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))\n",
    "\n",
    "np.shape(encoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c84abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c057c5",
   "metadata": {},
   "source": [
    "### 모델 형성 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f803a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "# 단어장의 크기 및 임베딩 벡터 차원입력\n",
    "enc_emb =  Embedding(4799, 8)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d6b9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 입력 텐서 생성.(교사 강요)\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "# 단어장의 크기 및 임베딩 벡터 차원입력\n",
    "fra_emb= Embedding(10009, 8)(decoder_inputs)\n",
    "decoder_lstm = LSTM(units=256, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(fra_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5beeaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 중 가장 확률이 높은 하나의 단어만 선택\n",
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f24d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84a2daf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 8)      80072       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  271360      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 10009)  2572313     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,923,745\n",
      "Trainable params: 2,923,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12c3978c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 7s 18ms/step - loss: 2.5279 - val_loss: 2.2142\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 1.7265 - val_loss: 2.0001\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 1.6105 - val_loss: 1.9228\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 1.5593 - val_loss: 1.8856\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 1.5188 - val_loss: 1.8643\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 1.4843 - val_loss: 1.8283\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 1.4545 - val_loss: 1.8078\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 1.4290 - val_loss: 1.7949\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.4066 - val_loss: 1.7867\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.3869 - val_loss: 1.7722\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.3689 - val_loss: 1.7656\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.3520 - val_loss: 1.7616\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.3359 - val_loss: 1.7444\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.3207 - val_loss: 1.7376\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.3070 - val_loss: 1.7349\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.2949 - val_loss: 1.7349\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.2835 - val_loss: 1.7364\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.2736 - val_loss: 1.7244\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.2643 - val_loss: 1.7246\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.2551 - val_loss: 1.7398\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.2466 - val_loss: 1.7194\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.2396 - val_loss: 1.7234\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.2329 - val_loss: 1.7223\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.2249 - val_loss: 1.7214\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.2177 - val_loss: 1.7170\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.2105 - val_loss: 1.7182\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.2036 - val_loss: 1.7140\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1986 - val_loss: 1.7183\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1937 - val_loss: 1.7090\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1891 - val_loss: 1.7059\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1828 - val_loss: 1.7183\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1781 - val_loss: 1.7096\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1732 - val_loss: 1.7134\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1677 - val_loss: 1.7164\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1623 - val_loss: 1.7114\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1573 - val_loss: 1.7173\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.1533 - val_loss: 1.7121\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.1499 - val_loss: 1.7169\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.1467 - val_loss: 1.7196\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.1434 - val_loss: 1.7283\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.1399 - val_loss: 1.7350\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.1364 - val_loss: 1.7306\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.1324 - val_loss: 1.7344\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.1287 - val_loss: 1.7398\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1262 - val_loss: 1.7662\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.1239 - val_loss: 1.7367\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1213 - val_loss: 1.7466\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1181 - val_loss: 1.7640\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1143 - val_loss: 1.7473\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 1.1101 - val_loss: 1.7440\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cafc5822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss') # bo는 파란색 점\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss') # b는 파란색 실선\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd72e733",
   "metadata": {},
   "source": [
    "### 모델 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70d53cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 8)           38392     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 271360    \n",
      "=================================================================\n",
      "Total params: 309,752\n",
      "Trainable params: 309,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = [state_h, state_c])\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d2d1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(None,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(None,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# decoder_lstm에 fra_emb 적용.\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(fra_emb, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "501d9d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 8)      80072       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   multiple             271360      embedding_1[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 10009)  2572313     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,923,745\n",
      "Trainable params: 2,923,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "010f0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "417fc73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1)) \n",
    "    target_seq[0, 0] = fra2idx['<sos>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장     \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "379fb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: go.\n",
      "정답 문장:  bouge ! \n",
      "번역기가 번역한 문장:  je suis un homm\n",
      "-----------------------------------\n",
      "입력 문장: hello!\n",
      "정답 문장:  bonjour ! \n",
      "번역기가 번역한 문장:  je suis un homm\n",
      "-----------------------------------\n",
      "입력 문장: got it?\n",
      "정답 문장:  t'as capté ? \n",
      "번역기가 번역한 문장:  je suis un homm\n",
      "-----------------------------------\n",
      "입력 문장: hang on.\n",
      "정답 문장:  tiens bon ! \n",
      "번역기가 번역한 문장:  je suis un homm\n",
      "-----------------------------------\n",
      "입력 문장: here's $5.\n",
      "정답 문장:  voilà cinq dollars. \n",
      "번역기가 번역한 문장:  je suis un homm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index])\n",
    "    print('정답 문장:', lines.fra[seq_index][5:len(lines.fra[seq_index])-5])\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7d00a",
   "metadata": {},
   "source": [
    "회고\n",
    "\n",
    "정말 NLP를 할 때마다 샐프 믹서기가 되는 느낌이다. 생명을 갈아 연명하는 삶이 이런 느낌일까? 늘 NLP는 어렵다. ML관련하여 가지고 있던 고질적인 문제를 다시 한번 맞이한 것 같다.  \n",
    "  \n",
    "가장 처음으로 마주한 어려움은 문자에서 단어로 바꿔어 토큰화를 시키는 것이었다. 토크나이저에 자동 필터가 달려있는데 이를 인지하지 못해서 '<sos>'와 '<eos>'가 제대로 나오지 않았고, 띄어쓰기를 하지 않아 토큰화도 이상하게 되었던 것을 데이터를 일일이 확인해가며 고칠 수 있었다.    \n",
    "    \n",
    "두번째 난관은 커널이 계속 죽는 것이었다. 모델을 만들고 .fit()으로 학습만 들어가면 커널이 계속 죽었는데, 매개변수 개수, 배치 크기 등을 변경시켜도 해결이 되지 않는 것이었다. 나중에 알고 보니 to_categorical함수로 one-hot encoding을 시켜준 것이 문제임을 확인하였다. 문자와 다르게, 단어는 사전의 크기가 매우 크기 때문에 one-hot encoding을 시키면 죽지 않는 것이 이상할 정도였음을 확인할 수 있었다. 게다가, 노드와 다르게 과제에서는 임배딩이 들어가기 때문에 애초에 one-hot encoding을 시킬 필요가 없었으니.. 이해가 많이 부족했구나 하는 생각이 들었다.  \n",
    "    \n",
    "세번째 난관은 번역 문장이 거의 같은 출력만 낸다는 점이다. 10개의 데이터를 넣으면 번역한 거의 다 같은 뜻으로 번역이 되는 것이다. 무엇이 문제인지, 원인을 찾아보려 했으나 결국 찾을 수 없었고. 미래의 나한테 맡기기로 하였다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9bd41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
